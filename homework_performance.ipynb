{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8f23e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1024, 1024])\n",
      "torch.Size([128, 512, 512])\n",
      "torch.Size([256, 256, 256])\n",
      "Используется устройство: CUDA\n",
      "\n",
      "\n",
      "Операция             | CPU (мс) | GPU (мс) |  Ускорение\n",
      "------------------------------------------------------------\n",
      "Матричное умножение  |     14.0 |      6.3 |       2.2x\n",
      "Сложение             |      3.0 |      3.3 |       0.9x\n",
      "Умножение            |      3.0 |      0.4 |       7.3x\n",
      "Транспонирование     |      0.0 |      0.0 |       0.0x\n",
      "Сумма всех элементов |      1.0 |      0.3 |       2.9x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Анализ данных:\\nисходя из полученной таблицы можно сделать выводы,что gpu работает лучше с большим набором данных и на сложных операциях,\\n на легких операциях и на мелньких данных разницы почти нет или иногда чуть лучше cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "tensor1 = torch.randint(0,1000,(64,1024,1024))\n",
    "print(tensor1.shape)\n",
    "tensor2 = torch.randint(0,1000,(128,512,512))\n",
    "print(tensor2.shape)\n",
    "tensor3 = torch.randint(0,1000,(256,256,256))\n",
    "print(tensor3.shape)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Используется устройство: {device.upper()}\")\n",
    "tensor1_cpu = torch.rand((16, 512, 512))\n",
    "tensor2_cpu = torch.rand((16, 512, 512))\n",
    "tensor3_cpu = torch.rand((16, 512, 512))\n",
    "\n",
    "\n",
    "\n",
    "# измерение времени\n",
    "def timetable(operation, device):\n",
    "    if device == 'cuda':\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "        start_event.record()\n",
    "    else:\n",
    "        start_time = time.time()\n",
    "    \n",
    "    result = operation()\n",
    "\n",
    "    if device == 'cuda':\n",
    "        end_event.record()\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed_time = start_event.elapsed_time(end_event) / 1000  \n",
    "    else:\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "    return result, elapsed_time\n",
    "\n",
    "#все оперцаии\n",
    "\n",
    "operations = {\n",
    "    \"Матричное умножение\": lambda t1, t2: lambda: torch.matmul(t1, t2),\n",
    "    \"Сложение\": lambda t1, t2: lambda: t1 + t2,\n",
    "    \"Умножение\": lambda t1, t2: lambda: t1 * t2,\n",
    "    \"Транспонирование\": lambda t1, _: lambda: t1.transpose(1, 2),\n",
    "    \"Сумма всех элементов\": lambda t1, _: lambda: torch.sum(t1)\n",
    "}\n",
    "\n",
    "# Таблица результатов\n",
    "results = []\n",
    "\n",
    "for name, op_func in operations.items():\n",
    "    \n",
    "\n",
    "    # --- На CPU ---\n",
    "  \n",
    "    _, cpu_time = timetable(op_func(tensor1_cpu, tensor2_cpu), 'cpu')\n",
    "    cpu_ms = cpu_time * 1000\n",
    "\n",
    "    # --- На GPU ---\n",
    "    if device == 'cuda':\n",
    "        tensor1_gpu = tensor1_cpu.cuda()\n",
    "        tensor2_gpu = tensor2_cpu.cuda()\n",
    "        _, gpu_time = timetable(op_func(tensor1_gpu, tensor2_gpu), 'cuda')\n",
    "        gpu_ms = gpu_time * 1000\n",
    "        speedup = cpu_ms / gpu_ms if gpu_ms > 0 else float('inf')\n",
    "    \n",
    "\n",
    "    results.append((name, cpu_ms, gpu_ms, speedup))\n",
    "\n",
    "# --- Вывод таблицы ---\n",
    "print(\"\\n\")\n",
    "print(\"{:<20} | {:>8} | {:>8} | {:>10}\".format(\"Операция\", \"CPU (мс)\", \"GPU (мс)\", \"Ускорение\"))\n",
    "print(\"-\" * 60)\n",
    "for row in results:\n",
    "    name, cpu_ms, gpu_ms, speedup = row\n",
    "    if isinstance(gpu_ms, str) or isinstance(speedup, str):\n",
    "        print(f\"{name:<20} | {cpu_ms:>8.1f} | {gpu_ms:>8} | {speedup:>10}\")\n",
    "    else:\n",
    "        print(f\"{name:<20} | {cpu_ms:>8.1f} | {gpu_ms:>8.1f} | {speedup:>9.1f}x\")\n",
    "\n",
    "\n",
    "''' Анализ данных:\n",
    "исходя из полученной таблицы можно сделать выводы,что gpu работает лучше с большим набором данных и на сложных операциях,\n",
    " на легких операциях и на мелньких данных разницы почти нет или иногда чуть лучше cpu'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3692f148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806d5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe07ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.4 Анализ результатов\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
